{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNesWTJI398LHGwXplFFU87",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Dhruv-958/BE/blob/main/ML_TicTacToe.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "g0QjiC9JStmT"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import random"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import random\n",
        "\n",
        "# a. Setting up the environment\n",
        "class TicTacToeEnv:\n",
        "    def __init__(self):\n",
        "        self.board = [' ' for _ in range(9)]\n",
        "        self.current_player = 'X'\n",
        "\n",
        "    def reset(self):\n",
        "        self.board = [' ' for _ in range(9)]\n",
        "        self.current_player = 'X'\n",
        "        return self.get_state()\n",
        "\n",
        "    def get_state(self):\n",
        "        return ''.join(self.board)\n",
        "\n",
        "    def step(self, action):\n",
        "        if self.board[action] == ' ':\n",
        "            self.board[action] = self.current_player\n",
        "            done, winner = self.check_game_over()\n",
        "            reward = 1 if winner == self.current_player else 0 if winner is None else -1\n",
        "            self.current_player = 'O' if self.current_player == 'X' else 'X'\n",
        "            return self.get_state(), reward, done\n",
        "        else:\n",
        "            return self.get_state(), -10, True  # Invalid move\n",
        "\n",
        "    def check_game_over(self):\n",
        "        winning_combinations = [\n",
        "            [0, 1, 2], [3, 4, 5], [6, 7, 8],  # Rows\n",
        "            [0, 3, 6], [1, 4, 7], [2, 5, 8],  # Columns\n",
        "            [0, 4, 8], [2, 4, 6]  # Diagonals\n",
        "        ]\n",
        "        for combo in winning_combinations:\n",
        "            if self.board[combo[0]] == self.board[combo[1]] == self.board[combo[2]] != ' ':\n",
        "                return True, self.board[combo[0]]\n",
        "        if ' ' not in self.board:\n",
        "            return True, None\n",
        "        return False, None\n",
        "\n",
        "    def render(self):\n",
        "        print(\"-------------\")\n",
        "        for i in range(3):\n",
        "            print(\"|\", self.board[i*3], \"|\", self.board[i*3+1], \"|\", self.board[i*3+2], \"|\")\n",
        "            print(\"-------------\")\n",
        "\n",
        "# b. Defining the Tic-Tac-Toe game\n",
        "class TicTacToeGame:\n",
        "    def __init__(self):\n",
        "        self.env = TicTacToeEnv()\n",
        "\n",
        "    def play_game(self, player1, player2):\n",
        "        state = self.env.reset()\n",
        "        done = False\n",
        "        while not done:\n",
        "            action = player1.choose_action(state) if self.env.current_player == 'X' else player2.choose_action(state)\n",
        "            next_state, reward, done = self.env.step(action)\n",
        "            if self.env.current_player == 'X':\n",
        "                player2.update(state, action, reward, next_state)\n",
        "            else:\n",
        "                player1.update(state, action, reward, next_state)\n",
        "            state = next_state\n",
        "        return reward\n",
        "\n",
        "# c. Building the reinforcement learning model\n",
        "class QLearningAgent:\n",
        "    def __init__(self, epsilon=0.1, alpha=0.5, gamma=0.9):\n",
        "        self.q_table = {}\n",
        "        self.epsilon = epsilon  # Exploration rate\n",
        "        self.alpha = alpha  # Learning rate\n",
        "        self.gamma = gamma  # Discount factor\n",
        "\n",
        "    def get_q_value(self, state, action):\n",
        "        return self.q_table.get((state, action), 0.0)\n",
        "\n",
        "    def choose_action(self, state):\n",
        "        if random.random() < self.epsilon:\n",
        "            return random.choice([i for i, spot in enumerate(state) if spot == ' '])\n",
        "        else:\n",
        "            q_values = [self.get_q_value(state, action) for action in range(9) if state[action] == ' ']\n",
        "            max_q = max(q_values)\n",
        "            best_actions = [action for action in range(9) if state[action] == ' ' and self.get_q_value(state, action) == max_q]\n",
        "            return random.choice(best_actions)\n",
        "\n",
        "    def update(self, state, action, reward, next_state):\n",
        "        best_next_action = max([self.get_q_value(next_state, a) for a in range(9) if next_state[a] == ' '], default=0)\n",
        "        td_target = reward + self.gamma * best_next_action\n",
        "        td_error = td_target - self.get_q_value(state, action)\n",
        "        self.q_table[(state, action)] = self.get_q_value(state, action) + self.alpha * td_error\n",
        "\n",
        "class HumanPlayer:\n",
        "    def choose_action(self, state):\n",
        "        while True:\n",
        "            try:\n",
        "                action = int(input(\"Enter your move (0-8): \"))\n",
        "                if 0 <= action <= 8 and state[action] == ' ':\n",
        "                    return action\n",
        "                else:\n",
        "                    print(\"Invalid move. Try again.\")\n",
        "            except ValueError:\n",
        "                print(\"Invalid input. Please enter a number between 0 and 8.\")\n",
        "\n",
        "    def update(self, state, action, reward, next_state):\n",
        "        pass  # Human doesn't need to update\n",
        "\n",
        "# d. Training the model\n",
        "def train_agent(episodes=10000):\n",
        "    agent = QLearningAgent()\n",
        "    game = TicTacToeGame()\n",
        "    for _ in range(episodes):\n",
        "        game.play_game(agent, agent)\n",
        "    return agent\n",
        "\n",
        "# e. Testing the model\n",
        "def test_agent(agent, episodes=1000):\n",
        "    game = TicTacToeGame()\n",
        "    random_player = QLearningAgent(epsilon=1.0)  # Always plays randomly\n",
        "    wins = 0\n",
        "    for _ in range(episodes):\n",
        "        reward = game.play_game(agent, random_player)\n",
        "        if reward == 1:\n",
        "            wins += 1\n",
        "    return wins / episodes\n",
        "\n",
        "# f. Human vs Computer gameplay\n",
        "def human_vs_computer(agent):\n",
        "    env = TicTacToeEnv()\n",
        "    human = HumanPlayer()\n",
        "    state = env.reset()\n",
        "    done = False\n",
        "\n",
        "    print(\"Welcome to Tic-Tac-Toe!\")\n",
        "    print(\"You are 'X', and the computer is 'O'.\")\n",
        "    print(\"Enter your moves using numbers 0-8, corresponding to the positions on the board:\")\n",
        "    print(\"0 | 1 | 2\")\n",
        "    print(\"3 | 4 | 5\")\n",
        "    print(\"6 | 7 | 8\")\n",
        "    print(\"\\nLet's begin!\")\n",
        "\n",
        "    while not done:\n",
        "        env.render()\n",
        "        if env.current_player == 'X':\n",
        "            action = human.choose_action(state)\n",
        "        else:\n",
        "            action = agent.choose_action(state)\n",
        "            print(f\"Computer chose: {action}\")\n",
        "\n",
        "        state, reward, done = env.step(action)\n",
        "\n",
        "        if done:\n",
        "            env.render()\n",
        "            if reward == 1:\n",
        "                winner = \"You\" if env.current_player == 'O' else \"Computer\"\n",
        "                print(f\"{winner} win!\")\n",
        "            elif reward == 0:\n",
        "                print(\"It's a draw!\")\n",
        "            return \"human\" if winner == \"You\" else \"computer\" if winner == \"Computer\" else \"draw\"\n",
        "\n",
        "# Main execution\n",
        "if __name__ == \"__main__\":\n",
        "    trained_agent = train_agent()\n",
        "    win_rate = test_agent(trained_agent)\n",
        "    print(f\"Agent win rate against random player: {win_rate:.2%}\")\n",
        "\n",
        "    play_again = 'y'\n",
        "    games_played = 0\n",
        "    computer_wins = 0\n",
        "    human_wins = 0\n",
        "    draws = 0\n",
        "\n",
        "    while play_again.lower() == 'y':\n",
        "        result = human_vs_computer(trained_agent)\n",
        "        games_played += 1\n",
        "        if result == \"computer\":\n",
        "            computer_wins += 1\n",
        "        elif result == \"human\":\n",
        "            human_wins += 1\n",
        "        else:\n",
        "            draws += 1\n",
        "\n",
        "        computer_win_rate = computer_wins / games_played\n",
        "        print(f\"\\nGames played: {games_played}\")\n",
        "        print(f\"Computer wins: {computer_wins}\")\n",
        "        print(f\"Human wins: {human_wins}\")\n",
        "        print(f\"Draws: {draws}\")\n",
        "        print(f\"Computer win rate: {computer_win_rate:.2%}\")\n",
        "        play_again = input(\"Do you want to play again? (y/n): \")\n",
        "\n",
        "    print(\"Thanks for playing!\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c7oJt8uuTDNK",
        "outputId": "7313829f-5676-44dc-f02f-9c6d7b3b3457"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Agent win rate against random player: 92.30%\n",
            "Welcome to Tic-Tac-Toe!\n",
            "You are 'X', and the computer is 'O'.\n",
            "Enter your moves using numbers 0-8, corresponding to the positions on the board:\n",
            "0 | 1 | 2\n",
            "3 | 4 | 5\n",
            "6 | 7 | 8\n",
            "\n",
            "Let's begin!\n",
            "-------------\n",
            "|   |   |   |\n",
            "-------------\n",
            "|   |   |   |\n",
            "-------------\n",
            "|   |   |   |\n",
            "-------------\n",
            "Enter your move (0-8): 0\n",
            "-------------\n",
            "| X |   |   |\n",
            "-------------\n",
            "|   |   |   |\n",
            "-------------\n",
            "|   |   |   |\n",
            "-------------\n",
            "Computer chose: 1\n",
            "-------------\n",
            "| X | O |   |\n",
            "-------------\n",
            "|   |   |   |\n",
            "-------------\n",
            "|   |   |   |\n",
            "-------------\n",
            "Enter your move (0-8): 8\n",
            "-------------\n",
            "| X | O |   |\n",
            "-------------\n",
            "|   |   |   |\n",
            "-------------\n",
            "|   |   | X |\n",
            "-------------\n",
            "Computer chose: 6\n",
            "-------------\n",
            "| X | O |   |\n",
            "-------------\n",
            "|   |   |   |\n",
            "-------------\n",
            "| O |   | X |\n",
            "-------------\n",
            "Enter your move (0-8): 2\n",
            "-------------\n",
            "| X | O | X |\n",
            "-------------\n",
            "|   |   |   |\n",
            "-------------\n",
            "| O |   | X |\n",
            "-------------\n",
            "Computer chose: 5\n",
            "-------------\n",
            "| X | O | X |\n",
            "-------------\n",
            "|   |   | O |\n",
            "-------------\n",
            "| O |   | X |\n",
            "-------------\n",
            "Enter your move (0-8): 4\n",
            "-------------\n",
            "| X | O | X |\n",
            "-------------\n",
            "|   | X | O |\n",
            "-------------\n",
            "| O |   | X |\n",
            "-------------\n",
            "You win!\n",
            "\n",
            "Games played: 1\n",
            "Computer wins: 0\n",
            "Human wins: 1\n",
            "Draws: 0\n",
            "Computer win rate: 0.00%\n",
            "Do you want to play again? (y/n): n\n",
            "Thanks for playing!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "y2lnPDAGhJmf"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}